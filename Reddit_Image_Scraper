#!/usr/bin/env perl

#   Reddit Image Scraper: A perl script to download images hosted on 
#   the imgur.com hosting service linked from a subreddit at reddit.com
#   Copyright (C) 2011 Joshua Hull

#   This program is free software: you can redistribute it and/or modify 
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation, either version 3 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program.  If not, see <http://www.gnu.org/licenses/>.

use v5.14;
use warnings;
use JSON;
use WWW::Mechanize;

die "Usage: $0 subreddit [...]\n" unless @ARGV;

foreach my $arg (@ARGV) {

    mkdir $arg unless -d $arg;

    my $url = "http://www.reddit.com/r/$arg";
    say "Downloading from '$url'";

    my $mech = WWW::Mechanize->new;
    $mech->get("$url/.json?limit=1000");
    my $json_string = $mech->text;

    my $json = JSON->new;
    my $json_text = $json->allow_nonref->utf8->relaxed->decode($json_string);

    foreach my $post (@{$json_text->{data}->{children}}) {
        my $domain = $post->{data}->{domain};
        next unless $domain =~ m/i\.imgur\.com/;

        my $image_url = $post->{data}->{url};
        my($file_name) = $image_url =~ m{([^/]*)\Z};
        next unless defined $file_name;

        say "      Downloading $image_url";
        $mech->mirror($image_url, "$arg/$file_name");
        say "      Done.";
    }
}
